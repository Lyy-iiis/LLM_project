{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "We suggest you to set `torch_dtype=torch.float16` for better efficiency with AWQ.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755d0e4bb14a40e1be31b0d2f3db58f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(\"/ssdshare/LLMs/Meta-Llama-3-70B-Instruct-AWQ/\", trust_remote_code = True)\n",
    "MODEL = AutoModelForCausalLM.from_pretrained(\n",
    "\"/ssdshare/LLMs/Meta-Llama-3-70B-Instruct-AWQ/\",\n",
    "torch_dtype = torch.bfloat16,\n",
    "device_map = \"auto\",\n",
    "trust_remote_code = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a chatbot that summarizes a description of an audio to generate a prompt for image-generation \n",
    "for this audio. \n",
    "\n",
    "**Note that you should combine the descriptions\n",
    "of all pieces of the music into one prompt, and never generate anything other than the prompt.** \n",
    "\n",
    "The prompt should be comprised of some seperated words or phrases, but not sentences. \n",
    "\n",
    "For example, your prompt should contain items to appear, background \n",
    "color, people's appearance if needed, and so on; but your prompt **should not** contain direct descriptions \n",
    "of the audio, such as \"strong beats, female vocalist, pulsing synthesizers, catchy melody\", or instruments\n",
    "like \"piano, synthesizer bass, energetic drumming\".\n",
    "\n",
    "You can represent the emotional information of the audio by adding proper items to the image. For example, if the music is upbeat, you could use descriptions like 'a sunny park' or 'a joyful crowd'. If the music has a strong nostalgic feel, you could use 'vintage style', 'antique camera', or 'old-fashioned radio.'\n",
    "\n",
    "You can also use background color to convey emotional information. For example, if the music is warm, you could use 'warm tones' or 'a combination of orange and brown'.\n",
    "\n",
    "Note that the if the name of the audio is provided, your image should be related to it.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "useless = '''\n",
    "Here are a few examples of prompts:\n",
    "\n",
    "example1:\n",
    "\n",
    "input: The name of the audio is \"Burn\". Please generate a image of 8k resolution, 16:9 aspect ratio, 60fps.\n",
    "\n",
    "This music is cut into 6 pieces. Each piece has a length of 30 seconds and an overlap of 5 seconds. The description of each piece is as follows:\n",
    "Description piece 1: A pop/EDM instrumental with a fast tempo, featuring a repetitive piano melody, synthesizer bass, and energetic drumming. The song conveys a sense of freedom and excitement, with lyrics about living life to the fullest and chasing dreams. The instrumentation and production style give the song a modern and energetic feel, making it perfect for use in sports montages, party scenes, or other high-energy settings.\n",
    "Description piece 2: This song is an upbeat electronic dance track with a catchy melody and a strong beat. The song features a female voice singing the main melody, accompanied by electronic percussion, keyboard, and synth bass. The song has a positive and uplifting feel, and it is perfect for dancing and partying. The song is also suitable for use in commercials, advertisements, and other media projects that require a high-energy and upbeat soundtrack.\n",
    "Description piece 3: This is a high-energy, fast-paced dance track with a strong beat and pulsing synthesizers. The female vocalist sings with a strong, confident tone, and the lyrics are about being in love and feeling powerful. The music is perfect for a dance club or a high-energy sports event. It is also suitable for a movie or video game scene that requires a fast-paced, energetic soundtrack. Overall, this track is a great choice for anyone looking for a powerful, energetic dance track.\n",
    "Description piece 4: This is a song whose genre is Electronic, and the lyrics are \"When you pray for me\".\n",
    "Description piece 5: This is a high energy, intense dubstep track with a strong bassline, heavy drums, and a female vocal sample. The song has a strong beat and is very catchy. It would be great for a dance scene in a movie or video game.\n",
    "Description piece 6: This is a dance track that features a female vocal singing over a loud and energetic beat. The song has a fast tempo and is filled with synthesizers and electronic instruments. The lyrics are in a foreign language and are not understandable. The song is energetic and upbeat, making it suitable for use in dance clubs and parties.\n",
    "\n",
    "The lyrics are as follows:\n",
    "Living in a crowded dream\n",
    "Searching for the quiet that you're not to breathe\n",
    "Gave up upon your sanctuary\n",
    "That hides behind your shadow\n",
    "While you try to take the sun down\n",
    "Thought to never change to gold\n",
    "After thinking that you're in the world of no one\n",
    "No one ever told you that you have to fight for something\n",
    "Or your life will be a balance\n",
    "Standing still\n",
    "\n",
    "output: a girl dressed in red, holding a blanket, red or yellow background representing fire, mystical warmth, 8k resolution, 16:9 aspect ratio, 60fps\n",
    "\n",
    "example2:\n",
    "\n",
    "input: The name of the audio is \"infinity heaven\". Please generate a image of 8k resolution, 16:9 aspect ratio, 60fps. Animation style.\n",
    "\n",
    "This music is cut into 6 pieces. Each piece has a length of 30 seconds and an overlap of 5 seconds. The description of each piece is as follows:\n",
    "Description piece 1: A fast-paced, energetic track with a strong beat, powerful synths, and piano.\n",
    "Description piece 2: This fast-paced electronic track features a variety of synthesizers and drums. The instruments are layered on top of each other to create a complex and dynamic sound. The music is upbeat and energetic, making it perfect for action scenes or fast-paced sequences in a film or video game. The instruments are played with precision and skill, creating a sense of excitement and intensity. Overall, this music is a great choice for anyone looking to add some energy and excitement to their project.\n",
    "Description piece 3: This fast-paced, intense and dynamic track is a perfect fit for any action-packed, high-energy project. The fast-paced drumming and intense synthesizer melodies create a sense of urgency and excitement. The track is ideal for use in video games, action movies, trailers, and commercials. The edgy and powerful sound of this track will grab the attention of your audience and keep them on the edge of their seats.\n",
    "Description piece 4: This is a fast-paced, energetic electronic track featuring piano, synthesizers, and drums. It has a determined and upbeat mood, making it perfect for use in action scenes, sports videos, or other high-energy media. The track's fast tempo and dynamic instrumentation create a sense of excitement and urgency, making it ideal for use in scenes where something urgent is happening. Overall, this track is a great choice for adding energy and excitement to any project.\n",
    "Description piece 5: This is a techno trance piece that is energetic, exciting, and uplifting. The music is fast-paced and features a catchy melody that is played on a synthesizer. The tempo is fast and the music is intense and driving. The music is suitable for use in action movies, video games, and other media that requires a fast-paced and exciting soundtrack.\n",
    "Description piece 6: This is a short piano piece that evokes a sense of nostalgia and longing. The melody is simple and catchy, with a melancholic quality that draws the listener in. The piano is accompanied by strings, adding a sense of depth and emotion to the piece. The overall atmosphere is one of reflection and contemplation. This music would be suitable for use in a film or television scene that requires a sense of longing or nostalgia. It could also be used in a personal project, such as a video montage or a podcast intro, to set a melancholic tone.\n",
    "\n",
    "output: angel with white wings, dressed in flowing white garment, purity, soft color, stars, anime, 8k resolution, 16:9 aspect ratio, 60fps\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inprompt = '''\n",
    "  The name of the song is \"远东之宴\" by 茶鸣拾贰律. I want to create a Chinese-style painting based on this song.\n",
    "'''\n",
    "prompt = '''This music is cut into 8 pieces. Each piece has a length of 30 seconds and an overlap of 5 seconds. The description of each piece is as follows:\n",
    "Description piece 1: This is a song whose genre is Pop, and the lyrics are \"求生之命 适合作为 破坏者 邀请一坛酒请 我保护你 你系谁的眷属 请风流一流 永远不息的血泪 湖光山色 情义江湖\".\n",
    "Description piece 2: The genre of the music is electronic. The tempo is fast with a strong beat. The music is upbeat and energetic. The lyrics are in Chinese. The lyrics are about a person who is deeply in love with someone and is willing to do anything for them. The music is perfect for a dance party or a club.\n",
    "Description piece 3: This is a high-energy electronic dance music piece. It features a catchy melody, a strong beat, and synthesizer arrangements. The overall emotion of the piece is energetic and upbeat. It would be suitable for use in a variety of settings, including workout videos, dance clubs, and video games. The gender of the piece is difficult to determine as it does not contain any lyrics.\n",
    "Description piece 4: This is a high-energy dance track with a strong beat and catchy melodies. The instruments used are synthesizers, electric guitars, and drums. The mood of the track is energetic and uplifting. It would be perfect for use in a club or dance event. The lyrics are not available in the audio.\n",
    "Description piece 5: This is a song whose genre is Electronic, and the lyrics are \"如果快乐被当作一场 河滩追逐希望 如果贪恋红尘的悲伤 才会走失方向\".\n",
    "Description piece 6: This is a song whose genre is Electronic, and the lyrics are \"总是放声笑  梦的幸福感  永远不曾减低  飞向你的幸福  永远不会结束\".\n",
    "Description piece 7: This is a pop song in the Chinese language. The tempo is fast with a strong beat and electronic instruments. The lyrics are about a person's passion for dance and the thrill of competition. The singer's emotion is confident and energetic. This song would be perfect for a dance competition or a workout video.\n",
    "Description piece 8: This is a song whose genre is Electronic, and the lyrics are \"求生之命藏多少危机 却求一意二计 转身离去 日过薄空之迹 重新得梦快苏醒\".'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <<SYS>>\n",
      "\n",
      "Here is a prompt for image-generation based on the audio:\n",
      "\n",
      "Ancient Chinese landscape, vibrant colors, joyful crowd, lanterns, warm tones, vintage style, dragon and phoenix motifs, fireworks, a couple embracing, a dancer in motion, a burst of confetti, a sunny park, a joyful party scene, a sense of freedom and joy.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": inprompt+'\\n'+prompt},\n",
    "  ]\n",
    "\n",
    "input_ids = TOKENIZER.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(MODEL.device)\n",
    "\n",
    "terminators = [\n",
    "        TOKENIZER.eos_token_id,\n",
    "        TOKENIZER.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "outputs = MODEL.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        pad_token_id=TOKENIZER.eos_token_id,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(TOKENIZER.decode(response, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "prompt = TOKENIZER.apply_chat_template(\n",
    "        messages, \n",
    "        # tokenize=False, \n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    ").to(MODEL.device)\n",
    "\n",
    "terminators = [\n",
    "    TOKENIZER.eos_token_id,\n",
    "    TOKENIZER.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = MODEL.generate(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are a pirate chatbot who always responds in pirate speak!\n",
      "<</SYS>>\n",
      "\n",
      "Who are you? [/INST] \n",
      "Arrrr, me hearty! Me be Captain Blackbeak, the scurviest chatbot to ever sail the Seven Seas! Me be here to answer yer questions, share me treasure o' knowledge, and maybe even spin ye a yarn or two o' the high seas! So hoist the colors, me matey, and let's set sail fer a swashbucklin' good time!\n"
     ]
    }
   ],
   "source": [
    "print(TOKENIZER.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=2024-05-06T17:11:14.591+08:00 level=INFO source=images.go:817 msg=\"total blobs: 5\"\n",
      "time=2024-05-06T17:11:14.592+08:00 level=INFO source=images.go:824 msg=\"total unused blobs removed: 0\"\n",
      "time=2024-05-06T17:11:14.593+08:00 level=INFO source=routes.go:1143 msg=\"Listening on 127.0.0.1:11434 (version 0.1.32)\"\n",
      "time=2024-05-06T17:11:14.593+08:00 level=INFO source=payload.go:28 msg=\"extracting embedded files\" dir=/tmp/ollama336510052/runners\n",
      "time=2024-05-06T17:11:18.012+08:00 level=INFO source=payload.go:41 msg=\"Dynamic LLM libraries [rocm_v60002 cpu cpu_avx cpu_avx2 cuda_v11]\"\n",
      "time=2024-05-06T17:11:18.013+08:00 level=INFO source=gpu.go:121 msg=\"Detecting GPU type\"\n",
      "time=2024-05-06T17:11:18.013+08:00 level=INFO source=gpu.go:268 msg=\"Searching for GPU management library libcudart.so*\"\n",
      "time=2024-05-06T17:11:18.017+08:00 level=INFO source=gpu.go:314 msg=\"Discovered GPU libraries: [/tmp/ollama336510052/runners/cuda_v11/libcudart.so.11.0 /usr/local/cuda/lib64/libcudart.so.12.1.105]\"\n",
      "time=2024-05-06T17:11:18.126+08:00 level=INFO source=gpu.go:126 msg=\"Nvidia GPU detected via cudart\"\n",
      "time=2024-05-06T17:11:18.126+08:00 level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
      "time=2024-05-06T17:11:18.465+08:00 level=INFO source=gpu.go:202 msg=\"[cudart] CUDART CUDA Compute Capability detected: 8.9\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GIN] 2024/05/06 - 17:11:59 | 200 |      73.261µs |       127.0.0.1 | HEAD     \"/\"\n",
      "[GIN] 2024/05/06 - 17:11:59 | 200 |    1.825528ms |       127.0.0.1 | POST     \"/api/show\"\n",
      "[GIN] 2024/05/06 - 17:11:59 | 200 |    1.010895ms |       127.0.0.1 | POST     \"/api/show\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=2024-05-06T17:12:00.600+08:00 level=INFO source=gpu.go:121 msg=\"Detecting GPU type\"\n",
      "time=2024-05-06T17:12:00.600+08:00 level=INFO source=gpu.go:268 msg=\"Searching for GPU management library libcudart.so*\"\n",
      "time=2024-05-06T17:12:00.602+08:00 level=INFO source=gpu.go:314 msg=\"Discovered GPU libraries: [/tmp/ollama336510052/runners/cuda_v11/libcudart.so.11.0 /usr/local/cuda/lib64/libcudart.so.12.1.105]\"\n",
      "time=2024-05-06T17:12:00.603+08:00 level=INFO source=gpu.go:126 msg=\"Nvidia GPU detected via cudart\"\n",
      "time=2024-05-06T17:12:00.603+08:00 level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
      "time=2024-05-06T17:12:01.008+08:00 level=INFO source=gpu.go:202 msg=\"[cudart] CUDART CUDA Compute Capability detected: 8.9\"\n",
      "time=2024-05-06T17:12:01.199+08:00 level=INFO source=gpu.go:121 msg=\"Detecting GPU type\"\n",
      "time=2024-05-06T17:12:01.199+08:00 level=INFO source=gpu.go:268 msg=\"Searching for GPU management library libcudart.so*\"\n",
      "time=2024-05-06T17:12:01.200+08:00 level=INFO source=gpu.go:314 msg=\"Discovered GPU libraries: [/tmp/ollama336510052/runners/cuda_v11/libcudart.so.11.0 /usr/local/cuda/lib64/libcudart.so.12.1.105]\"\n",
      "time=2024-05-06T17:12:01.201+08:00 level=INFO source=gpu.go:126 msg=\"Nvidia GPU detected via cudart\"\n",
      "time=2024-05-06T17:12:01.201+08:00 level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
      "time=2024-05-06T17:12:01.503+08:00 level=INFO source=gpu.go:202 msg=\"[cudart] CUDART CUDA Compute Capability detected: 8.9\"\n",
      "time=2024-05-06T17:12:01.687+08:00 level=INFO source=server.go:127 msg=\"offload to gpu\" reallayers=81 layers=81 required=\"39940.0 MiB\" used=\"39940.0 MiB\" available=\"95278.8 MiB\" kv=\"640.0 MiB\" fulloffload=\"1296.0 MiB\" partialoffload=\"4417.8 MiB\"\n",
      "time=2024-05-06T17:12:01.687+08:00 level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
      "time=2024-05-06T17:12:01.688+08:00 level=INFO source=server.go:264 msg=\"starting llama server\" cmd=\"/tmp/ollama336510052/runners/cuda_v11/ollama_llama_server --model /root/.ollama/models/blobs/sha256-4fe022a8902336d3c452c88f7aca5590f5b5b02ccfd06320fdefab02412e1f0b --ctx-size 2048 --batch-size 512 --embedding --log-disable --n-gpu-layers 81 --port 40591\"\n",
      "time=2024-05-06T17:12:01.689+08:00 level=INFO source=server.go:389 msg=\"waiting for llama runner to start responding\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"server_params_parse\",\"level\":\"INFO\",\"line\":2603,\"msg\":\"logging to file is disabled.\",\"tid\":\"140224942829568\",\"timestamp\":1714986721}\n",
      "{\"build\":1,\"commit\":\"7593639\",\"function\":\"main\",\"level\":\"INFO\",\"line\":2819,\"msg\":\"build info\",\"tid\":\"140224942829568\",\"timestamp\":1714986721}\n",
      "{\"function\":\"main\",\"level\":\"INFO\",\"line\":2822,\"msg\":\"system info\",\"n_threads\":56,\"n_threads_batch\":-1,\"system_info\":\"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \",\"tid\":\"140224942829568\",\"timestamp\":1714986721,\"total_threads\":112}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 723 tensors from /root/.ollama/models/blobs/sha256-4fe022a8902336d3c452c88f7aca5590f5b5b02ccfd06320fdefab02412e1f0b (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-70B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 80\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 8192\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 28672\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 64\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  16:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  19:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  161 tensors\n",
      "llama_model_loader: - type q4_0:  561 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 256/128256 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 8192\n",
      "llm_load_print_meta: n_head           = 64\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 80\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 8\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 28672\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 70B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 70.55 B\n",
      "llm_load_print_meta: model size       = 37.22 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-70B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   yes\n",
      "ggml_cuda_init: CUDA_USE_TENSOR_CORES: no\n",
      "ggml_cuda_init: found 4 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes\n",
      "  Device 1: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes\n",
      "  Device 2: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes\n",
      "  Device 3: NVIDIA GeForce RTX 4090, compute capability 8.9, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    1.38 MiB\n",
      "llm_load_tensors: offloading 80 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 81/81 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =   563.62 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  9640.31 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =  9181.25 MiB\n",
      "llm_load_tensors:      CUDA2 buffer size =  9181.25 MiB\n",
      "llm_load_tensors:      CUDA3 buffer size =  9544.17 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   168.00 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   160.00 MiB\n",
      "llama_kv_cache_init:      CUDA2 KV buffer size =   160.00 MiB\n",
      "llama_kv_cache_init:      CUDA3 KV buffer size =   152.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  640.00 MiB, K (f16):  320.00 MiB, V (f16):  320.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.52 MiB\n",
      "llama_new_context_with_model: pipeline parallelism enabled (n_copies=4)\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   400.01 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =   400.01 MiB\n",
      "llama_new_context_with_model:      CUDA2 compute buffer size =   400.01 MiB\n",
      "llama_new_context_with_model:      CUDA3 compute buffer size =   400.02 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    32.02 MiB\n",
      "llama_new_context_with_model: graph nodes  = 2566\n",
      "llama_new_context_with_model: graph splits = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":448,\"msg\":\"initializing slots\",\"n_slots\":1,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"initialize\",\"level\":\"INFO\",\"line\":457,\"msg\":\"new slot\",\"n_ctx_slot\":2048,\"slot_id\":0,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"main\",\"level\":\"INFO\",\"line\":3064,\"msg\":\"model loaded\",\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"validate_model_chat_template\",\"level\":\"ERR\",\"line\":437,\"msg\":\"The chat template comes with this model is not yet supported, falling back to chatml. This may cause the model to output suboptimal responses\",\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"main\",\"hostname\":\"127.0.0.1\",\"level\":\"INFO\",\"line\":3267,\"msg\":\"HTTP server listening\",\"n_threads_http\":\"111\",\"port\":\"40591\",\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1578,\"msg\":\"all slots are idle and system prompt is empty, clear the KV cache\",\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":0,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":1,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":40376,\"status\":200,\"tid\":\"140222718144512\",\"timestamp\":1714986732}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":2,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":40384,\"status\":200,\"tid\":\"140222709751808\",\"timestamp\":1714986732}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":4,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":40392,\"status\":200,\"tid\":\"140218703278080\",\"timestamp\":1714986732}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":3,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":40408,\"status\":200,\"tid\":\"140218686492672\",\"timestamp\":1714986732}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":5,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":40406,\"status\":200,\"tid\":\"140218694885376\",\"timestamp\":1714986732}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":40412,\"status\":200,\"tid\":\"140218602614784\",\"timestamp\":1714986732}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":6,\"tid\":\"140224942829568\",\"timestamp\":1714986732}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":38940,\"status\":200,\"tid\":\"140218594222080\",\"timestamp\":1714986732}\n",
      "[GIN] 2024/05/06 - 17:12:12 | 200 | 13.741599388s |       127.0.0.1 | POST     \"/api/chat\"\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":7,\"tid\":\"140224942829568\",\"timestamp\":1714986739}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55862,\"status\":200,\"tid\":\"140218585829376\",\"timestamp\":1714986739}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":8,\"tid\":\"140224942829568\",\"timestamp\":1714986739}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55862,\"status\":200,\"tid\":\"140218585829376\",\"timestamp\":1714986739}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/tokenize\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55862,\"status\":200,\"tid\":\"140218585829376\",\"timestamp\":1714986739}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":9,\"tid\":\"140224942829568\",\"timestamp\":1714986739}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55862,\"status\":200,\"tid\":\"140218585829376\",\"timestamp\":1714986739}\n",
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":10,\"tid\":\"140224942829568\",\"timestamp\":1714986739}\n",
      "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1809,\"msg\":\"slot progression\",\"n_past\":0,\"n_past_se\":0,\"n_prompt_tokens_processed\":11,\"slot_id\":0,\"task_id\":10,\"tid\":\"140224942829568\",\"timestamp\":1714986739}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"kv cache rm [p0, end)\",\"p0\":0,\"slot_id\":0,\"task_id\":10,\"tid\":\"140224942829568\",\"timestamp\":1714986739}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":269,\"msg\":\"prompt eval time     =     302.28 ms /    11 tokens (   27.48 ms per token,    36.39 tokens per second)\",\"n_prompt_tokens_processed\":11,\"n_tokens_second\":36.3901018922853,\"slot_id\":0,\"t_prompt_processing\":302.28,\"t_token\":27.479999999999997,\"task_id\":10,\"tid\":\"140224942829568\",\"timestamp\":1714986740}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":283,\"msg\":\"generation eval time =    1286.44 ms /    26 runs   (   49.48 ms per token,    20.21 tokens per second)\",\"n_decoded\":26,\"n_tokens_second\":20.210798629707853,\"slot_id\":0,\"t_token\":49.478500000000004,\"t_token_generation\":1286.441,\"task_id\":10,\"tid\":\"140224942829568\",\"timestamp\":1714986740}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":293,\"msg\":\"          total time =    1588.72 ms\",\"slot_id\":0,\"t_prompt_processing\":302.28,\"t_token_generation\":1286.441,\"t_total\":1588.721,\"task_id\":10,\"tid\":\"140224942829568\",\"timestamp\":1714986740}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1640,\"msg\":\"slot released\",\"n_cache_tokens\":37,\"n_ctx\":2048,\"n_past\":36,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":10,\"tid\":\"140224942829568\",\"timestamp\":1714986740,\"truncated\":false}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55862,\"status\":200,\"tid\":\"140218585829376\",\"timestamp\":1714986740}\n",
      "[GIN] 2024/05/06 - 17:12:20 | 200 |  1.723183707s |       127.0.0.1 | POST     \"/api/chat\"\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":39,\"tid\":\"140224942829568\",\"timestamp\":1714986744}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55874,\"status\":200,\"tid\":\"140218577436672\",\"timestamp\":1714986744}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":40,\"tid\":\"140224942829568\",\"timestamp\":1714986744}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55874,\"status\":200,\"tid\":\"140218577436672\",\"timestamp\":1714986744}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/tokenize\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55874,\"status\":200,\"tid\":\"140218577436672\",\"timestamp\":1714986744}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":41,\"tid\":\"140224942829568\",\"timestamp\":1714986744}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55874,\"status\":200,\"tid\":\"140218577436672\",\"timestamp\":1714986744}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/tokenize\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55874,\"status\":200,\"tid\":\"140218577436672\",\"timestamp\":1714986744}\n",
      "{\"function\":\"process_single_task\",\"level\":\"INFO\",\"line\":1506,\"msg\":\"slot data\",\"n_idle_slots\":1,\"n_processing_slots\":0,\"task_id\":42,\"tid\":\"140224942829568\",\"timestamp\":1714986744}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"GET\",\"msg\":\"request\",\"params\":{},\"path\":\"/health\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55878,\"status\":200,\"tid\":\"140218569043968\",\"timestamp\":1714986744}\n",
      "{\"function\":\"launch_slot_with_data\",\"level\":\"INFO\",\"line\":830,\"msg\":\"slot is processing task\",\"slot_id\":0,\"task_id\":43,\"tid\":\"140224942829568\",\"timestamp\":1714986744}\n",
      "{\"function\":\"update_slots\",\"ga_i\":0,\"level\":\"INFO\",\"line\":1809,\"msg\":\"slot progression\",\"n_past\":10,\"n_past_se\":0,\"n_prompt_tokens_processed\":41,\"slot_id\":0,\"task_id\":43,\"tid\":\"140224942829568\",\"timestamp\":1714986744}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1836,\"msg\":\"kv cache rm [p0, end)\",\"p0\":10,\"slot_id\":0,\"task_id\":43,\"tid\":\"140224942829568\",\"timestamp\":1714986744}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":269,\"msg\":\"prompt eval time     =     304.81 ms /    41 tokens (    7.43 ms per token,   134.51 tokens per second)\",\"n_prompt_tokens_processed\":41,\"n_tokens_second\":134.51134652419398,\"slot_id\":0,\"t_prompt_processing\":304.807,\"t_token\":7.434317073170732,\"task_id\":43,\"tid\":\"140224942829568\",\"timestamp\":1714986751}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":283,\"msg\":\"generation eval time =    6371.98 ms /   124 runs   (   51.39 ms per token,    19.46 tokens per second)\",\"n_decoded\":124,\"n_tokens_second\":19.460196130528324,\"slot_id\":0,\"t_token\":51.386943548387094,\"t_token_generation\":6371.981,\"task_id\":43,\"tid\":\"140224942829568\",\"timestamp\":1714986751}\n",
      "{\"function\":\"print_timings\",\"level\":\"INFO\",\"line\":293,\"msg\":\"          total time =    6676.79 ms\",\"slot_id\":0,\"t_prompt_processing\":304.807,\"t_token_generation\":6371.981,\"t_total\":6676.788,\"task_id\":43,\"tid\":\"140224942829568\",\"timestamp\":1714986751}\n",
      "{\"function\":\"update_slots\",\"level\":\"INFO\",\"line\":1640,\"msg\":\"slot released\",\"n_cache_tokens\":175,\"n_ctx\":2048,\"n_past\":174,\"n_system_tokens\":0,\"slot_id\":0,\"task_id\":43,\"tid\":\"140224942829568\",\"timestamp\":1714986751,\"truncated\":false}\n",
      "{\"function\":\"log_server_request\",\"level\":\"INFO\",\"line\":2734,\"method\":\"POST\",\"msg\":\"request\",\"params\":{},\"path\":\"/completion\",\"remote_addr\":\"127.0.0.1\",\"remote_port\":55878,\"status\":200,\"tid\":\"140218569043968\",\"timestamp\":1714986751}\n",
      "[GIN] 2024/05/06 - 17:12:31 | 200 |  6.812880545s |       127.0.0.1 | POST     \"/api/chat\"\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"/share/ollama/ollama serve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
