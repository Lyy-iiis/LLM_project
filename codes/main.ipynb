{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should call `.py` so that cuda memory will be automatically released after each part.\n",
    "\n",
    "This notebook is used to organize the codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need to do\n",
    "\n",
    "- Throw audio files into `data/` directory\n",
    "\n",
    "- Correctly set `input_list`\n",
    "\n",
    "- Create a `.env` file in the `process/` directory if using `glm-4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.getcwd() + '/data/'\n",
    "MODEL_PATH = '/ssdshare/LLMs/'\n",
    "MODEL = \"glm-4\"\n",
    "\n",
    "if not os.path.exists(DATA_PATH + '.tmp/'):\n",
    "  os.makedirs(DATA_PATH + '.tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "  'NceS - Burn.wav', \n",
    "  'HyuN - Infinity Heaven.wav'\n",
    "]\n",
    "with open(DATA_PATH + 'input_list.txt', 'w') as f:\n",
    "  for item in input_list:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "tmp_list = []\n",
    "for item in input_list:\n",
    "  tmp_list.append(item[:-4])\n",
    "input_list = tmp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NceS - Burn.wav\n",
      "HyuN - Infinity Heaven.wav\n",
      "['NceS - Burn.wav', 'HyuN - Infinity Heaven.wav']\n",
      "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [01:12<00:00,  8.04s/it]\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:04<00:00,  2.17it/s]\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.52it/s]\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device 0\n",
      "using device 1\n",
      "using device 2\n",
      "using device 3\n",
      "using device 0\n",
      "using device 1\n",
      "successfully add prompt for NceS - Burn.wav\n",
      "using device 2\n",
      "using device 3\n",
      "using device 0\n",
      "using device 1\n",
      "using device 2\n",
      "using device 3\n",
      "successfully add prompt for HyuN - Infinity Heaven.wav\n",
      "successfully write prompt for NceS - Burn.wav\n",
      "successfully write prompt for HyuN - Infinity Heaven.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python extract/extract.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --output_path {DATA_PATH}.tmp/extract/ --device_num 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in input_list:\n",
    "  with open(DATA_PATH + '.tmp/extract/' + file_name + '.prompt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NceS - Burn', 'HyuN - Infinity Heaven']\n",
      "<class 'zhipuai._client.ZhipuAI'> <class 'NoneType'>\n",
      "Token spent: 1997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python process/process.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --model {MODEL} --prompt_path {DATA_PATH}.tmp/extract/ --output_path {DATA_PATH}.tmp/process/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youthful energy, modern rebellion, freedom symbols, dance scene, passionate singer, catchy melodies, vibrant colors, dynamic movement, urban backdrop, edgy fashion, sunny park, joyful crowd, workout session, action movie, festival atmosphere, electronic synthesizers, gold accents, shadowy figures, sunlit scene, balance metaphor, rainstorm, magical atmosphere.\n",
      "energetic cityscape, action-ready figures, vibrant synth colors, dynamic motion, intense expressions, urban adrenaline, fast-paced, melodic contrasts, powerful basslines, rhythmic patterns, cinematic wonder, explorexplore, overcoming challenges, bold architecture, hopeful horizon.\n"
     ]
    }
   ],
   "source": [
    "for file_name in input_list:\n",
    "  with open(DATA_PATH + '.tmp/process/' + file_name + '.prompt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
