{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should call `.py` so that cuda memory will be automatically released after each part.\n",
    "\n",
    "This notebook is used to organize the codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need to do\n",
    "\n",
    "- Throw audio files into `data/` directory\n",
    "\n",
    "- Correctly set `input_list`\n",
    "\n",
    "- Create a `.env` file in the `process/` directory if using `glm-4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.getcwd() + '/data/'\n",
    "MODEL_PATH = '/ssdshare/LLMs/'\n",
    "MUSIC_PATH = os.getcwd() + '/data/music/'\n",
    "LLM_MODEL = \"glm-4\"\n",
    "GENRATE_MODEL = \"playground-v2.5-1024px-aesthetic\"\n",
    "CONTENT_PATH = DATA_PATH + '.tmp/generate/'\n",
    "STYLE_PATH = DATA_PATH + 'style/'\n",
    "\n",
    "if not os.path.exists(DATA_PATH + '.tmp/'):\n",
    "  os.makedirs(DATA_PATH + '.tmp/')\n",
    "\n",
    "list = ['extract/', 'generate/', 'process/', 'inprompt', 'style_transfer']\n",
    "\n",
    "for folder in list:\n",
    "  if not os.path.exists(DATA_PATH + '.tmp/' + folder):\n",
    "    os.makedirs(DATA_PATH + folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "  'FULi AUTO SHOOTER.mp3',\n",
    "]\n",
    "prompts = [r'''\n",
    "  The name of this song is 'FULi AUTO SHOOTER'. \n",
    "''',\n",
    "]\n",
    "# Pick the style images in the style library\n",
    "style_list = [\n",
    "  # 'opia.png'\n",
    "]\n",
    "# You should check both input_list and prompts modified!!!\n",
    "with open(DATA_PATH + 'input_list.txt', 'w') as f:\n",
    "  for item in input_list:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(DATA_PATH + 'style_list.txt', 'w') as f:\n",
    "  for item in style_list:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "\n",
    "tmp_list = []\n",
    "for item in input_list:\n",
    "  tmp_list.append(item[:-4])\n",
    "input_list = tmp_list\n",
    "\n",
    "# if not os.path.exists(DATA_PATH + '.tmp/inprompt/'):\n",
    "#   os.makedirs(DATA_PATH + '.tmp/inprompt/')\n",
    "for (prompt, name) in zip(prompts, input_list):\n",
    "  with open(DATA_PATH + '.tmp/inprompt/' + name + '.prompt', 'w') as f:\n",
    "    f.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULi AUTO SHOOTER.mp3\n",
      "['FULi AUTO SHOOTER.wav']\n",
      "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.56it/s]\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.64it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/LLM_project/codes/extract/extract.py\", line 173, in <module>\n",
      "    tmp, device_start = make_prompt(file_name[:-4], device_start = device_start)\n",
      "  File \"/root/LLM_project/codes/extract/extract.py\", line 152, in make_prompt\n",
      "    description, lyrics, device_start = partition_extract(file_name, device_start = device_start)\n",
      "  File \"/root/LLM_project/codes/extract/extract.py\", line 141, in partition_extract\n",
      "    description_piece, lyrics_piece = extract(f\"/{i}\", device = (i + device_start) % CUDA_NUM, path = TEMPORARY_PATH + file_name + \"/\")\n",
      "  File \"/root/LLM_project/codes/extract/extract.py\", line 102, in extract\n",
      "    decription, _ = models[device].chat(tokenizer, query = query, history = None, stream = False)\n",
      "  File \"/root/.cache/huggingface/modules/transformers_modules/modeling_qwen.py\", line 1176, in chat\n",
      "    assert stream is _SENTINEL, _ERROR_STREAM_IN_CHAT\n",
      "AssertionError: Pass argument `stream` to model.chat() is buggy, deprecated, and marked for removal. Please use model.chat_stream(...) instead of model.chat(..., stream=True).\n",
      "向model.chat()传入参数stream的用法可能存在Bug，该用法已被废弃，将在未来被移除。请使用model.chat_stream(...)代替model.chat(..., stream=True)。\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python extract/extract.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --music_path {MUSIC_PATH} --output_path {DATA_PATH}.tmp/extract/ --device_num 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This music is cut into 8 pieces. Each piece has a length of 30 seconds and an overlap of 5 seconds. The description of each piece is as follows:\n",
      "Description piece 1: This is a song whose genre is Pop, and the lyrics are \"求生之命 适合作为 破坏者 邀请一坛酒请 我保护你 你系谁的眷属 请风流一流 永远不息的血泪 湖光山色 情义江湖\".\n",
      "Description piece 2: The genre of the music is electronic. The tempo is fast with a strong beat. The music is upbeat and energetic. The lyrics are in Chinese. The lyrics are about a person who is deeply in love with someone and is willing to do anything for them. The music is perfect for a dance party or a club.\n",
      "Description piece 3: This is a high-energy electronic dance music piece. It features a catchy melody, a strong beat, and synthesizer arrangements. The overall emotion of the piece is energetic and upbeat. It would be suitable for use in a variety of settings, including workout videos, dance clubs, and video games. The gender of the piece is difficult to determine as it does not contain any lyrics.\n",
      "Description piece 4: This is a high-energy dance track with a strong beat and catchy melodies. The instruments used are synthesizers, electric guitars, and drums. The mood of the track is energetic and uplifting. It would be perfect for use in a club or dance event. The lyrics are not available in the audio.\n",
      "Description piece 5: This is a song whose genre is Electronic, and the lyrics are \"如果快乐被当作一场 河滩追逐希望 如果贪恋红尘的悲伤 才会走失方向\".\n",
      "Description piece 6: This is a song whose genre is Electronic, and the lyrics are \"总是放声笑  梦的幸福感  永远不曾减低  飞向你的幸福  永远不会结束\".\n",
      "Description piece 7: This is a pop song in the Chinese language. The tempo is fast with a strong beat and electronic instruments. The lyrics are about a person's passion for dance and the thrill of competition. The singer's emotion is confident and energetic. This song would be perfect for a dance competition or a workout video.\n",
      "Description piece 8: This is a song whose genre is Electronic, and the lyrics are \"求生之命藏多少危机 却求一意二计 转身离去 日过薄空之迹 重新得梦快苏醒\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name in input_list:\n",
    "  with open(DATA_PATH + '.tmp/extract/' + file_name + '.prompt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['茶鸣拾贰律 - Feast远东之宴']\n",
      "/root/LLM_project/codes/data/.tmp/inprompt/茶鸣拾贰律 - Feast远东之宴.prompt_total\n",
      "Loading model\n",
      "User return code: 0\n",
      "User output: \n",
      "User error: \u001b[?25l⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G⠇ \u001b[?25h\u001b[?25l\u001b[?25l\u001b[2K\u001b[1G\u001b[?25h\u001b[2K\u001b[1G\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python process/process.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --model {LLM_MODEL} --prompt_path {DATA_PATH}.tmp/extract/ --output_path {DATA_PATH}.tmp/process/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the prompts for image generation based on each piece:\n",
      "\n",
      "**Piece 1**\n",
      "Prompt: Vibrant nightclub scene with flashing lights, energetic dancers, and a DJ spinning tracks. Incorporate Chinese characters and symbols to reflect the song's lyrics.\n",
      "\n",
      "**Piece 2**\n",
      "Prompt: Futuristic cityscape at night with neon lights, fast cars, and a sense of excitement and energy. A couple embracing in the foreground, surrounded by dynamic lines and shapes.\n",
      "\n",
      "**Piece 3**\n",
      "Prompt: High-tech laboratory or futuristic gaming setup with sleek lines, neon accents, and a sense of intensity. Incorporate synthesizer-like patterns and shapes to reflect the music's electronic elements.\n",
      "\n",
      "**Piece 4**\n",
      "Prompt: Energetic dance party scene with strobing lights, confetti, and dancers in motion. Electric guitars and synthesizers visualized as vibrant, dynamic shapes.\n",
      "\n",
      "**Piece 5**\n",
      "Prompt: Dreamlike landscape with a river flowing through it, symbolizing hope and pursuit of happiness. Incorporate Chinese characters and watercolor-style brushstrokes to reflect the song's emotional tone.\n",
      "\n",
      "**Piece 6**\n",
      "Prompt: Uplifting, sunny scene with balloons, flowers, and smiling people. Incorporate elements that evoke a sense of joy, freedom, and happiness.\n",
      "\n",
      "**Piece 7**\n",
      "Prompt: Dynamic dance competition scene with spotlights, energetic dancers, and a confident singer in the foreground. Incorporate bold lines, shapes, and colors to reflect the song's upbeat tempo.\n",
      "\n",
      "**Piece 8**\n",
      "Prompt: Mysterious, futuristic landscape with glowing orbs, neon accents, and a sense of adventure. Incorporate elements that evoke a sense of danger, risk, and pursuit of dreams.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name in input_list:\n",
    "  with open(DATA_PATH + '.tmp/process/' + file_name + '.prompt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prompt from file\n",
      "茶鸣拾贰律 - Feast远东之宴.prompt\n",
      "Prompt loaded\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.26it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA GeForce RTX 4090 with CUDA capability sm_89 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA GeForce RTX 4090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Generating for 茶鸣拾贰律 - Feast远东之宴.prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (322 > 77). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (322 > 77). Running this sequence through the model will result in indexing errors\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/LLM_project/codes/generate/generate.py\", line 102, in <module>\n",
      "    output = pipe(prompt[audio], \n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/.cache/huggingface/modules/diffusers_modules/local/lpw_stable_diffusion_xl.py\", line 1628, in __call__\n",
      "    ) = get_weighted_text_embeddings_sdxl(\n",
      "  File \"/root/.cache/huggingface/modules/diffusers_modules/local/lpw_stable_diffusion_xl.py\", line 361, in get_weighted_text_embeddings_sdxl\n",
      "    prompt_embeds_1 = pipe.text_encoder(token_tensor.to(device), output_hidden_states=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/clip/modeling_clip.py\", line 804, in forward\n",
      "    return self.text_model(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/clip/modeling_clip.py\", line 697, in forward\n",
      "    hidden_states = self.embeddings(input_ids=input_ids, position_ids=position_ids)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/clip/modeling_clip.py\", line 222, in forward\n",
      "    inputs_embeds = self.token_embedding(input_ids)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 158, in forward\n",
      "    return F.embedding(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 2199, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "RuntimeError: CUDA error: no kernel image is available for execution on the device\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python generate/generate.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --model {GENRATE_MODEL} --output_path {DATA_PATH}.tmp/generate/ --prompt_path {DATA_PATH}.tmp/process/ --image_num 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the style transfer model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Style Loss : 0.222865 Content Loss: 1.303105: 100%|██████████| 300/300 [00:33<00:00,  9.00it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the style transfer model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Style Loss : 0.000000 Content Loss: 0.000000:  94%|█████████▎| 281/300 [00:28<00:01,  9.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python style_transfer/style_transfer.py --data_path {DATA_PATH} --output_path {DATA_PATH}.tmp/style_transfer/ --style_path {STYLE_PATH} --content_path {CONTENT_PATH} -c_p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
