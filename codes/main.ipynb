{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should call `.py` so that cuda memory will be automatically released after each part.\n",
    "\n",
    "This notebook is used to organize the codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need to do\n",
    "\n",
    "- Throw audio files into `data/` directory\n",
    "\n",
    "- Correctly set `input_list`\n",
    "\n",
    "- Create a `.env` file in the `process/` directory if using `glm-4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.getcwd() + '/data/'\n",
    "MODEL_PATH = '/ssdshare/LLMs/'\n",
    "MUSIC_PATH = os.getcwd() + '/data/music/'\n",
    "LLM_MODEL = \"glm-4\"\n",
    "GENRATE_MODEL = \"playground-v2.5-1024px-aesthetic\"\n",
    "CONTENT_PATH = DATA_PATH + '.tmp/generate/'\n",
    "STYLE_PATH = DATA_PATH + 'style/illustration_style/'\n",
    "\n",
    "if not os.path.exists(DATA_PATH + '.tmp/'):\n",
    "  os.makedirs(DATA_PATH + '.tmp/')\n",
    "\n",
    "list = ['extract/', 'generate/', 'process/', 'inprompt', 'style_transfer']\n",
    "\n",
    "for folder in list:\n",
    "  if not os.path.exists(DATA_PATH + '.tmp/' + folder):\n",
    "    os.makedirs(DATA_PATH + '.tmp/' + folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "  'NceS - Burn.mp3',\n",
    "]\n",
    "prompts = [r'''\n",
    "  The name of this song is 'NceS - Burn'. \n",
    "''',\n",
    "]\n",
    "# Pick the style images in the style library\n",
    "style_list = [\n",
    "  # 'opia.png'\n",
    "]\n",
    "# You should check both input_list and prompts modified!!!\n",
    "with open(DATA_PATH + 'input_list.txt', 'w') as f:\n",
    "  for item in input_list:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(DATA_PATH + 'style_list.txt', 'w') as f:\n",
    "  for item in style_list:\n",
    "    f.write(\"%s\\n\" % item)\n",
    "\n",
    "tmp_list = []\n",
    "for item in input_list:\n",
    "  tmp_list.append(item[:-4])\n",
    "input_list = tmp_list\n",
    "\n",
    "# if not os.path.exists(DATA_PATH + '.tmp/inprompt/'):\n",
    "#   os.makedirs(DATA_PATH + '.tmp/inprompt/')\n",
    "for (prompt, name) in zip(prompts, input_list):\n",
    "  with open(DATA_PATH + '.tmp/inprompt/' + name + '.prompt', 'w') as f:\n",
    "    f.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NceS - Burn.mp3\n",
      "['NceS - Burn.wav']\n",
      "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.36it/s]\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.38it/s]\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.38it/s]\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 9/9 [00:03<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device 0\n",
      "using device 1\n",
      "using device 2\n",
      "using device 3\n",
      "using device 0\n",
      "using device 1\n",
      "successfully add prompt for NceS - Burn.wav\n",
      "successfully write prompt for NceS - Burn.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python extract/extract.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --music_path {MUSIC_PATH} --output_path {DATA_PATH}.tmp/extract/ --device_num 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This music is cut into 6 pieces. Each piece has a length of 30 seconds and an overlap of 5 seconds. The description of each piece is as follows:\n",
      "Description piece 1: This piece of music is a pop song with a female vocalist. It has a light and airy feel, with a gentle acoustic guitar and soft drums providing the rhythmic background. The melody is catchy and easy to sing along to, with a repetitive chorus that creates a sense of unity and togetherness. The lyrics are about finding beauty and peace in the world around us, and the importance of living in the moment and embracing life's challenges. Overall, this song is a feel-good, uplifting anthem that encourages listeners to live their best lives and find happiness in the simple things.\n",
      "Description piece 2: This is a song whose genre is Pop, and the lyrics are \"So cold standing in the middle of the dark forest Oh my love because it's only you When you crash and burn\".\n",
      "Description piece 3: This is a high-energy electronic dance music piece. The female vocalist sings in a passionate and determined tone. The instrumental features a pounding kick drum, synthesizers, and a repetitive bassline. The atmosphere is intense and exciting. This piece could be used in the soundtrack of an action movie or video game.\n",
      "Description piece 4: This is a high-energy dubstep track with a female vocal hook. The song starts with a powerful bassline and energetic drumming, leading into the vocal hook. The female vocal is passionate and energetic, with a strong sense of determination. The song has a strong dance groove and is perfect for a club or festival setting. The lyrics are not available in the audio.\n",
      "Description piece 5: This is a song whose genre is Electronic, and the lyrics are \"I'm not a dreamer I'm a fighter\".\n",
      "Description piece 6: This is a song whose genre is Electronic, and the lyrics are \" I can't believe it's true\".\n",
      "\n",
      "The lyrics are as follows:\n",
      "Living in a crowded dream\n",
      "Searching for the quiet that you're not to breathe\n",
      "Gave up upon your sanctuary\n",
      "Hiding behind your shadow\n",
      "While you tried to take the sun down\n",
      "Thought to never change to gold\n",
      "After thinking that you're in the world of aloha\n",
      "No one ever told you that you have to fight for something\n",
      "Or your balance to balance\n",
      "Too cold\n",
      "You're standing in the middle of the downpour\n",
      "And when you're here with me I'm a winner\n",
      "Every single day\n",
      "I'll make sure you're mine\n",
      "I'm so happy I'm so happy I'm so happy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name in input_list:\n",
    "  with open(DATA_PATH + '.tmp/extract/' + file_name + '.prompt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FULi AUTO SHOOTER']\n",
      "Loading model\n",
      "Model loaded\n",
      "<class 'zhipuai._client.ZhipuAI'> <class 'NoneType'>\n",
      "Token spent: 6699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python process/process.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --model {LLM_MODEL} --prompt_path {DATA_PATH}.tmp/extract/ --output_path {DATA_PATH}.tmp/process/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamic cyberpunk cityscape, neon lights, futuristic vehicles, male protagonist in focus, intense expression, wearing high-tech gear, red and black color scheme, abstract patterns, strong shadows, glowing elements, sense of motion, urban chaos, 8k resolution, 16:9 aspect ratio, 60fps.\n"
     ]
    }
   ],
   "source": [
    "for file_name in input_list:\n",
    "  with open(DATA_PATH + '.tmp/process/' + file_name + '.prompt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prompt from file\n",
      "FULi AUTO SHOOTER.prompt\n",
      "Prompt loaded\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Generating for FULi AUTO SHOOTER.prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated for FULi AUTO SHOOTER.prompt\n",
      "Generating image without characters\n",
      "Loading prompt from file\n",
      "Prompt loaded\n",
      "Generating for FULi AUTO SHOOTER.prompt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (84 > 77). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (84 > 77). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated for FULi AUTO SHOOTER.prompt2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'python generate/generate.py --model_path {MODEL_PATH} --data_path {DATA_PATH} --model {GENRATE_MODEL} --output_path {DATA_PATH}.tmp/generate/ --prompt_path {DATA_PATH}.tmp/process/ --image_num 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring from /root/LLM_project/codes/data/.tmp/generate/FULi AUTO SHOOTER/0.png to /root/LLM_project/codes/data/style/illustration_style/7.png\n",
      "Building the style transfer model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Style Loss : 5.652418 Content Loss: 1.724384:  54%|█████▎    | 161/300 [00:17<00:15,  8.93it/s] "
     ]
    }
   ],
   "source": [
    "os.system(f'python style_transfer/style_transfer.py --data_path {DATA_PATH} --output_path {DATA_PATH}.tmp/style_transfer/ --style_path {STYLE_PATH} --content_path {CONTENT_PATH} -l_o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
