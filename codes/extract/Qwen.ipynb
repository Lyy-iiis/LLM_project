{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".mp3 to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./\"\n",
    "audio_file_name = \"NceS - Burn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='./NceS - Burn.wav'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mp3 to wav\n",
    "audio = AudioSegment.from_mp3(DATA_PATH + audio_file_name + \".mp3\")\n",
    "audio = audio.set_channels(1)\n",
    "audio.export(DATA_PATH + audio_file_name + \".wav\", format = \"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen-Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: transformers>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 1)) (4.38.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 2)) (0.27.2)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 4)) (0.8.0)\n",
      "Requirement already satisfied: transformers_stream_generator>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 5)) (0.0.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 7)) (0.16.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 8)) (10.0.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 9)) (2.16.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r Qwen_requirements.txt (line 10)) (3.8.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r Qwen_requirements.txt (line 2)) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r Qwen_requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (1.62.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (68.0.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r Qwen_requirements.txt (line 9)) (3.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r Qwen_requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r Qwen_requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r Qwen_requirements.txt (line 10)) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r Qwen_requirements.txt (line 10)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r Qwen_requirements.txt (line 10)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r Qwen_requirements.txt (line 10)) (2.8.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.32.0->-r Qwen_requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r Qwen_requirements.txt (line 2)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r Qwen_requirements.txt (line 2)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r Qwen_requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r Qwen_requirements.txt (line 9)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate->-r Qwen_requirements.txt (line 2)) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r Qwen_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f51342d3530>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import torch\n",
    "import os\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/ssdshare/LLMs/\"\n",
    "PWD = os.getcwd()\n",
    "DATA_PATH = './'\n",
    "if DATA_PATH[0] == '.' :\n",
    "    DATA_PATH = PWD + \"/\" + DATA_PATH\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "assert DEVICE == \"cuda\", \"WHY DONT YOU HAVE CUDA???????\"\n",
    "TEMPORARY_PATH = DATA_PATH + \".tmp/\"\n",
    "if not os.path.exists(TEMPORARY_PATH) :\n",
    "    os.makedirs(TEMPORARY_PATH)\n",
    "CUDA_NUM = torch.cuda.device_count()\n",
    "if CUDA_NUM == 1 :\n",
    "    print(\"WARNING : Only 1 GPU may cause some problems.\")\n",
    "CUDA_DEVICE = [f\"cuda:{i}\" for i in range(CUDA_NUM)]\n",
    "WINDOW_SIZE = 30_000\n",
    "OVERLAP_SIZE = 5_000\n",
    "OUTPUT_FILE = \"extract_output.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_start_id: 155163, audio_end_id: 155164, audio_pad_id: 151851.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93409810fbcd42bf92ebee96c8d217b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cce51e59e94fc1bcce6ec1a09a8b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c1266a4a734fcaad12fa4fed0102dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874882149d184ff5b46b68730ca49a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH + \"Qwen-Audio-Chat/\", trust_remote_code = True)\n",
    "\n",
    "# use bf16\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio-Chat\", device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
    "# use fp16\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-Audio-Chat\", device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
    "models = []\n",
    "for device in CUDA_DEVICE :\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_PATH + \"Qwen-Audio-Chat/\", device_map = device, trust_remote_code = True).eval()\n",
    "    models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pop/EDM instrumental with synthesizers, acoustic guitars, and a catchy beat. The lyrics are about living life to the fullest and chasing dreams.\n",
      "The lyrics are:\"Living in a crowded place, searching for the quiet that you're not to breathe, Give up upon your sanctuary, hide behind your shadow, While you try to take the sun down, ought to never change your gold, After thinking that you're in the world of no one, No one ever told you that you have to fight for something, Or your life will be too cold\".\n"
     ]
    }
   ],
   "source": [
    "query = tokenizer.from_list_format([\n",
    "    {'audio': DATA_PATH + audio_file_name + '.wav'}, # Either a local path or an url\n",
    "    {'text': 'Please give a detailed description of this piece of music, with no less than 5 sentences. Remind that you should give the description of the music, not the lyrics.'},\n",
    "])\n",
    "response, history = models[0].chat(tokenizer, query=query, history=None)\n",
    "print(response)\n",
    "# The person says: \"mister quilter is the apostle of the middle classes and we are glad to welcome his gospel\".\n",
    "\n",
    "# 2nd dialogue turn\n",
    "response, history = models[0].chat(tokenizer, 'Extract all the lyrics if the music has.', history=history)\n",
    "print(response)\n",
    "# The word \"middle classes\" starts at <|2.33|> seconds and ends at <|3.26|> seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition&Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaningful_lyrics(lyrics) :\n",
    "    if \"NOLYRICS\" in lyrics :\n",
    "        return False\n",
    "    if len(lyrics) < 100 :\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def extract(file_name, device = 0, path = DATA_PATH) :\n",
    "    query = tokenizer.from_list_format([\n",
    "        {'audio': path + file_name + '.wav'}, \n",
    "        {'text': 'Please give a detailed description (emotion, background) of this piece of music, with no less than 5 sentences. You should give 5 sentences, not the lyrics, not words. '},\n",
    "    ])\n",
    "    decription, _ = models[device].chat(tokenizer, query = query, history = None)\n",
    "\n",
    "    query = tokenizer.from_list_format([\n",
    "        {'audio': path + file_name + '.wav'},\n",
    "        {'text': 'Extract all the lyrics of this music if it has. Say \"NOLYRICS\" if it does not have lyrics or the lyrics are meaningless.'},\n",
    "    ])\n",
    "    \n",
    "    lyrics, _ = models[device].chat(tokenizer, query = query, history = None)\n",
    "    if not meaningful_lyrics(lyrics) :\n",
    "        lyrics = None\n",
    "    else :\n",
    "        lyrics = lyrics.split('\"')[1]\n",
    "    return decription, lyrics\n",
    "\n",
    "# test\n",
    "# description, lyrics = extract(\"HyuN - Infinity Heaven\")\n",
    "# print(description)\n",
    "# print(lyrics)\n",
    "# description, lyrics = extract(\"NceS - Burn\")\n",
    "# print(description)\n",
    "# print(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read, write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_extract(file_name, no_clear = False) :\n",
    "    #####################################\n",
    "    # I don't recommend parallel because running the same model continiously causes problems.\n",
    "    #####################################\n",
    "    file_name = file_name + ''\n",
    "    audio = AudioSegment.from_wav(DATA_PATH + file_name + \".wav\")\n",
    "    duration = len(audio)\n",
    "    num_of_pieces = (duration - OVERLAP_SIZE) // (WINDOW_SIZE - OVERLAP_SIZE) + 1\n",
    "    file_name = file_name.replace(\" \", \"_\")\n",
    "    if not os.path.exists(TEMPORARY_PATH) :\n",
    "        os.makedirs(TEMPORARY_PATH)\n",
    "    if not os.path.exists(TEMPORARY_PATH + file_name) :\n",
    "        os.makedirs(TEMPORARY_PATH + file_name)\n",
    "\n",
    "    description = []\n",
    "    lyrics = []\n",
    "\n",
    "\n",
    "    for i in range(num_of_pieces) :\n",
    "        start = i * (WINDOW_SIZE - OVERLAP_SIZE)\n",
    "        end = start + WINDOW_SIZE\n",
    "        if end > duration :\n",
    "            end = duration\n",
    "        piece = audio[start:end]\n",
    "        piece.export(TEMPORARY_PATH + file_name + f\"/{i}.wav\", format = \"wav\")\n",
    "        description_piece, lyrics_piece = extract(f\"/{i}\", device = i % CUDA_NUM, path = TEMPORARY_PATH + file_name + \"/\")\n",
    "        description.append(description_piece)\n",
    "        lyrics.append(lyrics_piece)\n",
    "\n",
    "    if not no_clear :\n",
    "        os.system(f\"rm -rf {TEMPORARY_PATH + file_name + '/'}\")\n",
    "\n",
    "    return description, lyrics\n",
    "\n",
    "# test\n",
    "# description, lyrics = partition_extract('NceS - Burn')\n",
    "# print(description)\n",
    "# print(lyrics)\n",
    "# description, lyrics = partition_extract('HyuN - Infinity Heaven')\n",
    "# print(description)\n",
    "# print(lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "description, lyrics = partition_extract(audio_file_name)\n",
    "prompt = f\"This music is cut into {len(description)} pieces. Each piece has a length of {WINDOW_SIZE // 1000} seconds and an overlap of {OVERLAP_SIZE // 1000} seconds. The description of each piece is as follows:\\n\"\n",
    "for i, d in enumerate(description) :\n",
    "    prompt += f\"Description piece {i + 1}: {d}\\n\"\n",
    "\n",
    "have_lyrics = False\n",
    "for l in lyrics :\n",
    "    if l is not None :\n",
    "        have_lyrics = True\n",
    "        break\n",
    "\n",
    "if have_lyrics :\n",
    "    prompt += f\"\\nThe lyrics are as follows:\\n\"\n",
    "    for i, l in enumerate(lyrics) :\n",
    "        if l is not None :\n",
    "            prompt += f\"{l}\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEMPORARY_PATH + OUTPUT_FILE, \"w\") as f :\n",
    "    f.write(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
