{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install invisible_watermark transformers safetensors\n",
    "!pip install diffusers==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14339f3141b409f9703eb6f62c3d709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionXLPipeline {\n",
       "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
       "  \"_diffusers_version\": \"0.28.0.dev0\",\n",
       "  \"_name_or_path\": \"/ssdshare/LLMs/stable-diffusion-xl-base-1.0_incomplete/\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"force_zeros_for_empty_prompt\": true,\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"EulerDiscreteScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\"/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# if using torch < 2.0\n",
    "# pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c80ce618cbf40ffac1dcdf46644c0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=1024x1024 at 0x7F0ABE485240>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"An astronaut riding a green horse\"\n",
    "images = pipe(prompt=prompt).images[0]\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\"generate_example\", exist_ok=True)\n",
    "\n",
    "# Save the image\n",
    "\n",
    "images.save(\"generate_example/1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866e36ed023a4bfe9be5f83cced20e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63b1f4a40ba4b2c9b3da93d333e80c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "# load both base & refiner\n",
    "base = DiffusionPipeline.from_pretrained(\n",
    "    \"/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "base.to(\"cuda\")\n",
    "refiner = DiffusionPipeline.from_pretrained(\n",
    "    \"/ssdshare/LLMs/stable-diffusion-xl-refiner-1.0/\",\n",
    "    text_encoder_2=base.text_encoder_2,\n",
    "    vae=base.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    ")\n",
    "refiner.to(\"cuda\")\n",
    "\n",
    "# Define how many steps and what % of steps to be run on each experts (80/20) here\n",
    "n_steps = 40\n",
    "high_noise_frac = 0.8\n",
    "\n",
    "prompt = \"A majestic lion jumping from a big stone at night\"\n",
    "\n",
    "# run both experts\n",
    "image_base = base(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    # denoising_end=high_noise_frac,\n",
    "    output_type=\"latent\",\n",
    ").images\n",
    "\n",
    "image = refiner(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    # denoising_start=high_noise_frac,\n",
    "    image=image_base,\n",
    ").images[0]\n",
    "image.save(\"generate_example/refined.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2b667f1d2e4b33a1db3252185c626e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919bf9e3696c4212b1402af7575dc405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_steps = 100\n",
    "high_noise_frac = 0.8\n",
    "\n",
    "prompt = \"Jay Chou playing the piano in a concert, with realistic style\"\n",
    "\n",
    "# run both experts\n",
    "image_base = base(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    # denoising_end=high_noise_frac,\n",
    "    output_type=\"latent\",\n",
    ").images\n",
    "\n",
    "image = refiner(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    # denoising_start=high_noise_frac,\n",
    "    image=image_base,\n",
    ").images[0]\n",
    "image.save(\"generate_example/person_real.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19aca45efe4f43f0b60a371348d954a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4bd7d2c7064049b0074f96372229b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "# load both base & refiner\n",
    "base = DiffusionPipeline.from_pretrained(\n",
    "    \"/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "base.to(\"cuda:1\")\n",
    "refiner = DiffusionPipeline.from_pretrained(\n",
    "    \"/ssdshare/LLMs/stable-diffusion-xl-refiner-1.0/\",\n",
    "    text_encoder_2=base.text_encoder_2,\n",
    "    vae=base.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    ").to(\"cuda:1\")\n",
    "n_steps = 50\n",
    "high_noise_frac = 0.8\n",
    "\n",
    "prompt = \"Jay Chou in a fantasy world, playing piano, 8k resolution, 16:9 aspect ratio, 60fps, with a dreamy aesthetic.\"\n",
    "image_base = base(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    # denoising_end=high_noise_frac,\n",
    "    output_type=\"latent\",\n",
    ").images\n",
    "\n",
    "image = refiner(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=n_steps,\n",
    "    # denoising_start=high_noise_frac,\n",
    "    image=image_base,\n",
    ").images[0]\n",
    "image.save(\"generate_example/jay_real.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
