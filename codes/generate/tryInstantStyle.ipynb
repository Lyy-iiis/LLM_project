{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting modelscope\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/fd/67/f0d513d698358227fbabbfbd531dd2ada8706f324b12f773755035c6d9c2/modelscope-1.14.0-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting addict (from modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from modelscope) (23.1.0)\n",
      "Requirement already satisfied: datasets<2.19.0,>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.17.1)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.8.0)\n",
      "Requirement already satisfied: filelock>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (3.9.0)\n",
      "Collecting gast>=0.2.2 (from modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/fa/39/5aae571e5a5f4de9c3445dae08a530498e5c53b0e74410eeeb0991c79047/gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from modelscope) (0.21.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.26.0)\n",
      "Collecting oss2 (from modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/61/ce/d23a9d44268dc992ae1a878d24341dddaea4de4ae374c261209bb6e9554b/oss2-2.18.5.tar.gz (283 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.4/283.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.2.1)\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (10.0.1)\n",
      "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (15.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from modelscope) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.25 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.31.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from modelscope) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from modelscope) (68.0.0)\n",
      "Collecting simplejson>=3.3.0 (from modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/cb/b6/ed513a0adc3e2c9654864ffb68266dcab5720d5653428d690e7e4fb32a6c/simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m771.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sortedcontainers>=1.5.9 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from modelscope) (4.65.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from modelscope) (2.2.1)\n",
      "Collecting yapf (from modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/66/c9/d4b03b2490107f13ebd68fe9496d41ae41a7de6275ead56d0d4621b11ffd/yapf-0.40.2-py3-none-any.whl (254 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets<2.19.0,>=2.16.0->modelscope) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (3.9.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets<2.19.0,>=2.16.0->modelscope) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->modelscope) (4.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.1->modelscope) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2023.7.22)\n",
      "Collecting crcmod>=1.7 (from oss2->modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6b/b0/e595ce2a2527e169c3bcd6c33d2473c1918e0b7f6826a043ca1245dd4e5b/crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pycryptodome>=3.4.7 (from oss2->modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/af/20/5f29ec45462360e7f61e8688af9fe4a0afae057edfabdada662e11bf97e7/pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2->modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3d/ea/d88e08bfc4a0aee0111f1f24c98b19107bc6783441e7e944907c77b2243d/aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2->modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/3a/e6/f579e8a5e26ef1066f6fb11074cedc9f668cb5f722c85cf7adc0f7e2e23e/aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->modelscope) (2024.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (6.11.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (4.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->modelscope) (2.0.1)\n",
      "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (41.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<2.19.0,>=2.16.0->modelscope) (4.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->modelscope) (3.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (2.21)\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.18.5-py3-none-any.whl size=118146 sha256=95dad36d794de5ffee6a19cefc370f9acf94887ec10a5ddbba864170406d5ce1\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/7e/1a/d9c9a87db4a4cb751811017112fd5b10a9658da9d8f6fe41a4\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=a7a3f673ec527af877b5234047ea50650247c8a816f2fb477818393cb369afee\n",
      "  Stored in directory: /root/.cache/pip/wheels/2f/bd/89/02cd85ecd77defbce5a0585de6b9a82f111d6e1ec1945fccd9\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23519 sha256=9a4ca20b6d721f56824415ce3582b402f9b493e1a9ab1e27ba412388439953ae\n",
      "  Stored in directory: /root/.cache/pip/wheels/aa/64/0d/d371a836ec27ec35ef16ce7b8dae4898f6e1ffb309268bfceb\n",
      "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
      "Installing collected packages: crcmod, addict, simplejson, pycryptodome, jmespath, gast, yapf, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, modelscope\n",
      "Successfully installed addict-2.4.0 aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.2 crcmod-1.7 gast-0.5.4 jmespath-0.10.0 modelscope-1.14.0 oss2-2.18.5 pycryptodome-3.20.0 simplejson-3.19.2 yapf-0.40.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "StableDiffusionXLPipeline.encode_prompt() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m image\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# generate image variations with only image prompt\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mip_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpil_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma cat, masterpiece, best quality, high quality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnegative_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext, watermark, lowres, low quality, worst quality, deformed, glitch, low contrast, noisy, saturation, blurry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m#neg_content_prompt=\"a rabbit\",\u001b[39;49;00m\n\u001b[1;32m     45\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;66;43;03m#neg_content_scale=0.5,\u001b[39;49;00m\n\u001b[1;32m     46\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/llm_course_public/project_try/InstantStyle/ip_adapter/ip_adapter.py:305\u001b[0m, in \u001b[0;36mIPAdapterXL.generate\u001b[0;34m(self, pil_image, prompt, negative_prompt, scale, num_samples, seed, num_inference_steps, neg_content_emb, neg_content_prompt, neg_content_scale, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m uncond_image_prompt_embeds \u001b[38;5;241m=\u001b[39m uncond_image_prompt_embeds\u001b[38;5;241m.\u001b[39mview(bs_embed \u001b[38;5;241m*\u001b[39m num_samples, seq_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[1;32m    300\u001b[0m     (\n\u001b[1;32m    301\u001b[0m         prompt_embeds,\n\u001b[1;32m    302\u001b[0m         negative_prompt_embeds,\n\u001b[1;32m    303\u001b[0m         pooled_prompt_embeds,\n\u001b[1;32m    304\u001b[0m         negative_pooled_prompt_embeds,\n\u001b[0;32m--> 305\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_images_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_classifier_free_guidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnegative_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     prompt_embeds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([prompt_embeds, image_prompt_embeds], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    312\u001b[0m     negative_prompt_embeds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([negative_prompt_embeds, uncond_image_prompt_embeds], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: StableDiffusionXLPipeline.encode_prompt() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "from PIL import Image\n",
    "\n",
    "from ip_adapter import IPAdapterXL\n",
    "\n",
    "base_model_path = \"/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\"\n",
    "image_encoder_path = \"sdxl_models/image_encoder\"\n",
    "ip_ckpt = \"sdxl_models/ip-adapter_sdxl.bin\"\n",
    "device = \"cuda\"\n",
    "\n",
    "# load SDXL pipeline\n",
    "# pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "#     base_model_path,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     add_watermarker=False,\n",
    "# )\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "# reduce memory consumption\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "# load ip-adapter\n",
    "# target_blocks=[\"block\"] for original IP-Adapter\n",
    "# target_blocks=[\"up_blocks.0.attentions.1\"] for style blocks only\n",
    "# target_blocks = [\"up_blocks.0.attentions.1\", \"down_blocks.2.attentions.1\"] # for style+layout blocks\n",
    "ip_model = IPAdapterXL(pipe, image_encoder_path, ip_ckpt, device, target_blocks=[\"up_blocks.0.attentions.1\"])\n",
    "\n",
    "image = \"./assets/0.jpg\"\n",
    "image = Image.open(image)\n",
    "image.resize((512, 512))\n",
    "\n",
    "# generate image variations with only image prompt\n",
    "images = ip_model.generate(pil_image=image,\n",
    "                            prompt=\"a cat, masterpiece, best quality, high quality\",\n",
    "                            negative_prompt= \"text, watermark, lowres, low quality, worst quality, deformed, glitch, low contrast, noisy, saturation, blurry\",\n",
    "                            scale=1.0,\n",
    "                            guidance_scale=5,\n",
    "                            num_samples=1,\n",
    "                            num_inference_steps=30, \n",
    "                            seed=42,\n",
    "                            #neg_content_prompt=\"a rabbit\",\n",
    "                            #neg_content_scale=0.5,\n",
    "                          )\n",
    "\n",
    "images[0].save(\"result.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use in diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StableDiffusionXLPipeline' object has no attribute 'load_ip_adapter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m pipe \u001b[38;5;241m=\u001b[39m DiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m, use_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# load ip-adapter\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_ip_adapter\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh94/IP-Adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m, subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdxl_models\u001b[39m\u001b[38;5;124m\"\u001b[39m, weight_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mip-adapter_sdxl.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m pipe\u001b[38;5;241m.\u001b[39menable_vae_tiling()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# configure ip-adapter scales.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/configuration_utils.py:137\u001b[0m, in \u001b[0;36mConfigMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    134\u001b[0m     deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirect config name access\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, deprecation_message, standard_warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_dict[name]\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StableDiffusionXLPipeline' object has no attribute 'load_ip_adapter'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# load SDXL pipeline\n",
    "# pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "#     \"/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     add_watermarker=False,\n",
    "# )\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"/ssdshare/LLMs/stable-diffusion-xl-base-1.0/\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "\n",
    "# load ip-adapter\n",
    "pipe.load_ip_adapter(\"h94/IP-Adapter\", subfolder=\"sdxl_models\", weight_name=\"ip-adapter_sdxl.bin\")\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "# configure ip-adapter scales.\n",
    "scale = {\n",
    "    \"down\": {\"block_2\": [0.0, 1.0]},\n",
    "    \"up\": {\"block_0\": [0.0, 1.0, 0.0]},\n",
    "}\n",
    "pipeline.set_ip_adapter_scale(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for original IP-Adapter\n",
    "scale = 1.0\n",
    "pipeline.set_ip_adapter_scale(scale)\n",
    "\n",
    "# for style blocks only\n",
    "scale = {\n",
    "    \"up\": {\"block_0\": [0.0, 1.0, 0.0]},\n",
    "}\n",
    "pipeline.set_ip_adapter_scale(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple IP-Adapter images with masks \n",
    "seems no need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hidiffusion import apply_hidiffusion, remove_hidiffusion\n",
    "\n",
    "# reduce memory consumption\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "# apply hidiffusion with a single line of code.\n",
    "apply_hidiffusion(pipe)\n",
    "\n",
    "...\n",
    "\n",
    "# generate image at higher resolution\n",
    "images = ip_model.generate(pil_image=image,\n",
    "                           prompt=\"a cat, masterpiece, best quality, high quality\",\n",
    "                           negative_prompt= \"text, watermark, lowres, low quality, worst quality, deformed, glitch, low contrast, noisy, saturation, blurry\",\n",
    "                           scale=1.0,\n",
    "                           guidance_scale=5,\n",
    "                           num_samples=1,\n",
    "                           num_inference_steps=30, \n",
    "                           seed=42,\n",
    "                           height=2048,\n",
    "                           width=2048\n",
    "                          )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
