{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use in diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c61d00a90f641788c4cc202f34fa8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "from PIL import Image\n",
    "\n",
    "from ip_adapter import IPAdapterXL\n",
    "\n",
    "base_model_path = \"/ssdshare/LLMs/stable-diffusion-xl-base-0.9/\"\n",
    "image_encoder_path = \"/ssdshare/LLMs/h94-IP-Adapter/sdxl_models/image_encoder/\"\n",
    "ip_ckpt = \"/ssdshare/LLMs/h94-IP-Adapter/sdxl_models/ip-adapter_sdxl.bin\"\n",
    "device = \"cuda\"\n",
    "\n",
    "# load SDXL pipeline\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    add_watermarker=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d5c8b0058643d39a5c2ed540c595b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# reduce memory consumption\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "# load ip-adapter\n",
    "# target_blocks=[\"block\"] for original IP-Adapter\n",
    "# target_blocks=[\"up_blocks.0.attentions.1\"] for style blocks only\n",
    "# target_blocks = [\"up_blocks.0.attentions.1\", \"down_blocks.2.attentions.1\"] # for style+layout blocks\n",
    "ip_model = IPAdapterXL(pipe, image_encoder_path, ip_ckpt, \"cuda:1\", target_blocks=[\"up_blocks.0.attentions.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def pil_to_cv2(image_pil):\n",
    "    image_np = np.array(image_pil)\n",
    "    image_cv2 = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
    "    return image_cv2\n",
    "def resize_img(\n",
    "    input_image,\n",
    "    max_side=1280,\n",
    "    min_side=1024,\n",
    "    size=None,\n",
    "    pad_to_max_side=False,\n",
    "    mode=Image.BILINEAR,\n",
    "    base_pixel_number=64,\n",
    "):\n",
    "    w, h = input_image.size\n",
    "    if size is not None:\n",
    "        w_resize_new, h_resize_new = size\n",
    "    else:\n",
    "        ratio = min_side / min(h, w)\n",
    "        w, h = round(ratio * w), round(ratio * h)\n",
    "        ratio = max_side / max(h, w)\n",
    "        input_image = input_image.resize([round(ratio * w), round(ratio * h)], mode)\n",
    "        w_resize_new = (round(ratio * w) // base_pixel_number) * base_pixel_number\n",
    "        h_resize_new = (round(ratio * h) // base_pixel_number) * base_pixel_number\n",
    "    input_image = input_image.resize([w_resize_new, h_resize_new], mode)\n",
    "\n",
    "    if pad_to_max_side:\n",
    "        res = np.ones([max_side, max_side, 3], dtype=np.uint8) * 255\n",
    "        offset_x = (max_side - w_resize_new) // 2\n",
    "        offset_y = (max_side - h_resize_new) // 2\n",
    "        res[\n",
    "            offset_y : offset_y + h_resize_new, offset_x : offset_x + w_resize_new\n",
    "        ] = np.array(input_image)\n",
    "        input_image = Image.fromarray(res)\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea21fa356e94fc09a926e77c20004c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"Create a detailed and refined image of Zero Two from the anime Darling in the Franxx. She is known for her distinctive pink hair and mesmerizing green eyes. She should be depicted in a dynamic pose, showcasing her strong and fearless personality. The image should be in anime style, with an 8k resolution and a 16:9 aspect ratio. The background should be a battlefield, symbolizing the constant fights she has to face. Despite the harsh environment, she maintains a confident and determined expression. The background should be black.\"\n",
    "prompt = \"Ganyu from Genshin Impact, blue hair and blue eyes, horns and a long ponytail, a blue and white outfit with cloud patterns and gold accents, in an elegant pose, standing in front of a scenic background like mountains, a waterfall, graceful, fantastical, 8k resolution, 16:9 aspect ratio, comic style\"\n",
    "\n",
    "image = \"Zero Two.png\"\n",
    "image = Image.open(image)\n",
    "image.resize((512, 512))\n",
    "\n",
    "input_image = \"sqa.jpg\"\n",
    "input_image = Image.open(input_image)\n",
    "if input_image is not None:\n",
    "    input_image = resize_img(input_image, max_side=1024)\n",
    "    cv_input_image = pil_to_cv2(input_image)\n",
    "    detected_map = cv2.Canny(cv_input_image, 50, 200)\n",
    "    canny_map = Image.fromarray(cv2.cvtColor(detected_map, cv2.COLOR_BGR2RGB))\n",
    "else:\n",
    "    canny_map = Image.new('RGB', (1024, 1024), color=(255, 255, 255))\n",
    "    control_scale = 0\n",
    "\n",
    "# generate image variations with only image prompt\n",
    "images = ip_model.generate(pil_image=image,\n",
    "                            prompt=\"a man, masterpiece, best quality, high quality\",\n",
    "                            negative_prompt= \"text, watermark, lowres, low quality, worst quality, deformed, glitch, low contrast, noisy, saturation, blurry\",\n",
    "                            scale=1.0,\n",
    "                            guidance_scale=5,\n",
    "                            num_samples=1,\n",
    "                            num_inference_steps=60, \n",
    "                            seed=42,\n",
    "                            image=canny_map,\n",
    "                            #neg_content_prompt=\"a rabbit\",\n",
    "                            #neg_content_scale=0.5,\n",
    "                          )\n",
    "\n",
    "images[0].save(\"result.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Resolution Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hidiffusion import apply_hidiffusion, remove_hidiffusion\n",
    "\n",
    "# reduce memory consumption\n",
    "pipe.enable_vae_tiling()\n",
    "\n",
    "# apply hidiffusion with a single line of code.\n",
    "apply_hidiffusion(pipe)\n",
    "\n",
    "...\n",
    "\n",
    "# generate image at higher resolution\n",
    "images = ip_model.generate(pil_image=image,\n",
    "                           prompt=\"a cat, masterpiece, best quality, high quality\",\n",
    "                           negative_prompt= \"text, watermark, lowres, low quality, worst quality, deformed, glitch, low contrast, noisy, saturation, blurry\",\n",
    "                           scale=1.0,\n",
    "                           guidance_scale=5,\n",
    "                           num_samples=1,\n",
    "                           num_inference_steps=30, \n",
    "                           seed=42,\n",
    "                           height=2048,\n",
    "                           width=2048\n",
    "                          )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
